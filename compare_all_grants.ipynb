{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54e917c5-d1e6-4e16-88ac-45f199f240ba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Compare All Grants Between HMS and Destination\n",
    "\n",
    "Used Widgets: \n",
    "* Destination Catalog -- Type in what catalog you are migrating to\n",
    "\n",
    "Ignored Widgets:\n",
    "* Scan Catalog (always uses hive_metastore)\n",
    "* Scan Database (always looks at all databases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39e51d4b-2f08-49ca-b747-a71c782e1afa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Initialization\n",
    "You will have to run both of these code cells in this section each time you reconnect to the cluster.\n",
    "\n",
    "Note: The usage of \"from ... import\" works expects a single .py file, as included from github.\n",
    "If you are not using github repos, create a notebook with the DbInventoryCollector.py file's contents in it, and change this line to read:\n",
    "\n",
    "```%run ./Db-Inventory-Collector```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa5ee101-0a71-4cbb-a4f4-4c253c3b79d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from DbInventoryCollector import InventoryCollector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0f1dfa6-2da4-4b3f-851d-1bffc1e6a71a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "#Create Widgets\n",
    "InventoryCollector.CreateWidgets(dbutils, spark, reset=False)\n",
    "\n",
    "#Instantiate and initialize collector class\n",
    "collector = InventoryCollector(spark, dbutils.widgets.get(\"Inventory_Catalog\"), dbutils.widgets.get(\"Inventory_Database\"))\n",
    "collector.initialize()\n",
    "\n",
    "#This pulls out the widget values to a python variable.\n",
    "#Paste these lines into a cell to enable automatic execution on widget change\n",
    "destCatalog = dbutils.widgets.get(\"Migration_Catalog\")\n",
    "\n",
    "if destCatalog == \"ChangeMeToDest\":\n",
    "    raise Exception(\"You must set the destination catalog using the widgets above\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21932455-8fb8-488e-ac5a-9090c9cc6e91",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Scanning Databases\n",
    "\n",
    "Scan both the HMS and destination catalogs for their grants, rescanning previous results to get the latest data.\n",
    "Commented by default for speed purposes. Rescanning hive is optional, rescanning the destination catalog is **required**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cced84cf-1c93-472d-8f9f-0b79c47e87c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# collector.scan_all_databases(\"hive_metastore\", scanObjects = False, scanGrants = True, rescan = True)\n",
    "# collector.scan_all_databases(destCatalog, scanObjects = False, scanGrants = True, rescan = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4276f4b8-bc46-4807-a194-ed41dd9618bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Compare Grants Between Hive_Metastore and Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97537599-4efd-4a08-aded-0b714c0ffce4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "allGrants_hive = spark.sql(f\"\"\"\n",
    "WITH ranked_grants AS (\n",
    "    SELECT *,\n",
    "    RANK() OVER (PARTITION BY source_catalog,source_database ORDER BY execution_time DESC) as rank\n",
    "    FROM {collector.inventory_catdb}.grant_statements)\n",
    "SELECT source_database, ObjectType, ActionType, ObjectKey, Principal, grant_statement\n",
    "FROM ranked_grants\n",
    "WHERE source_catalog = \"hive_metastore\" AND rank = 1\n",
    "order by source_database, ObjectType, ObjectKey\n",
    "\"\"\")\n",
    "\n",
    "allGrants_dest = spark.sql(f\"\"\"\n",
    "WITH ranked_grants AS (\n",
    "    SELECT *,\n",
    "    RANK() OVER (PARTITION BY source_catalog,source_database ORDER BY execution_time DESC) as rank\n",
    "    FROM {collector.inventory_catdb}.grant_statements)\n",
    "SELECT source_database, ObjectType, ActionType, ObjectKey, Principal, grant_statement\n",
    "FROM ranked_grants\n",
    "WHERE source_catalog = \"{destCatalog}\" AND rank = 1\n",
    "order by source_database, ObjectType, ObjectKey\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "joinColumns = [\"source_database\", \"Principal\", \"ActionType\", \"ObjectType\", \"ObjectKey\"]\n",
    "allGrants_hive = allGrants_hive.select(\"source_database\", \"Principal\", \"ObjectType\", \"ObjectKey\", \n",
    "                                       col(\"ActionType\").alias(\"HiveAction\"),\n",
    "                                       when(col(\"ActionType\") == \"USAGE\", \"USE SCHEMA\")\n",
    "                                       .when(col(\"ActionType\") == \"CREATE_NAMED_FUNCTION\", \"CREATE FUNCTION\")\n",
    "                                       .when(col(\"ActionType\") == \"CREATE\", \"CREATE TABLE\")\n",
    "                                       .otherwise(col(\"ActionType\")).alias(\"ActionType\")\n",
    "    ).filter('ActionType != \"READ_METADATA\" AND ActionType != \"OWN\"')\n",
    "\n",
    "grantCompare_both = allGrants_hive.join(allGrants_dest, joinColumns, how = \"inner\")\n",
    "grantCompare_hiveOnly = allGrants_hive.join(allGrants_dest, joinColumns, how = \"left_anti\")\n",
    "grantCompare_destOnly = allGrants_dest.join(allGrants_hive, joinColumns, how = \"left_anti\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dd44d27-5ce1-4dd9-92d7-cbe282a637b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(grantCompare_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7699048-e539-4f6c-8fa4-8e8f578c8103",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(grantCompare_hiveOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fea15ff-0a4f-4726-a4a0-6d6bbe1a991f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(grantCompare_destOnly)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DDL for Missing Grants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiveGrantTodo = grantCompare_hiveOnly.drop('ActionType').withColumnRenamed('HiveAction', 'ActionType')\n",
    "hiveGrantsString = collector.generate_migration_grant_sql(hiveGrantTodo, destCatalog)\n",
    "hiveGrantsList = collector.split_sql_to_list(hiveGrantsString)\n",
    "\n",
    "print(f\"Generated {len(hiveGrantsList)} Grants to reconcile catalog {destCatalog} with hive_metastore:\\n\")\n",
    "print(hiveGrantsString)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute Missing Grants\n",
    "collector.execute_sql_list(hiveGrantsList, echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescan potentially changed databases to update our results\n",
    "missingDbs = [r.source_database for r in grantCompare_hiveOnly.select(\"source_database\").distinct().collect()]\n",
    "collector.scan_all_databases(destCatalog, rescan=True, scanObjects=False, scanGrants=True, databaseScanList=missingDbs)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "09_compare_grants_all_clean",
   "notebookOrigID": 2788332189278390,
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
